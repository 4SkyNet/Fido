\subsection{Software Plans}

Currently, the number of wires that our neural network outputs is constant. However, the complexity of the functions that the wire-fitting function has to model varies from task to task. To add to the portability of Fido, we plan on implementing a method of dynamically changing the number of wires that the neural network outputs. Such a method would gage the variance and bias that the interpolator is experiencing. Variance is the deviation of a function from its mean. The wire-fitting function's variance could be measured in a range of actions. Bias is the error that results from under fitting, and could be measured as the moving average of the wire-fitted interpolator function's error at predicting Q-values, or the moving average of the distance that the wire-fitting function's wires have to move during gradient descent. Our proposed method would use $bias^2 + variance$ as a cost function and would look to reduce its by testing changes to the number of wires to determine the direction of the cost function. Each time a wire is removed or added to create a new set of wires, this set of wires will be changed to best model the wire-fitting function formed by the past set of wires.

The topology of our feedforward neural networks is static throughout Fido's lifetime. To increase the generality of Fido, we would like to research ways to evolve the topology of Fido's neural network as performs action and receives reward. This may mean measuring variance and bias values and determining the direction of $bias^2 + variance$ as outlined above, but may also take the form of an existing variation of back propagation, of which there are many.

\subsection{Hardware Implementation}