\documentclass[letterpaper,12pt]{article}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[nottoc]{tocbibind}
\usepackage[margin=1.5in]{geometry}
\usepackage{mathptmx}
\usepackage[activate={true,nocompatibility},final,
			tracking=true,kerning=true,spacing=true,
			factor=1100,stretch=10,shrink=10]{microtype}
\usepackage{amsmath,setspace} \long\def\/*#1*/{}
\doublespacing

\begin{document}

\/*

The Executive Summary on its own, separate from the Research Report, should convey the essence of your project and should be understood by someone without scientific expertise. Do not simply replicate what you wrote in your Abstract. The summary should clearly present three content areas - the question asked, the methods used and the lessons learned and must be written in layperson (non-specialist) language. NOTE: The summary will be used to explain your project to the general public and in preparing press releases for the media.

*/

\begin{center}
	{\Large
	\textbf{A General Robotic Control System using Reinforcement Learning with Limited Feedback}}\\
	\vspace{1cm}
	{\large \textbf{Executive Summary}}
\end{center}

\noindent

A robot intelligence can be simplified into a black box, with inputs such as sensor data and outputs such as motor control.  The purpose of this project was to develop an intelligence that not only can adapt to any set of robot inputs and outputs, but can also be trained using positive and negative reinforcement.  The implementation is lightweight and resource-efficient, making it a practical solution as a control system for mobile robots.  This was achieved by regulating artificial neural networks according to a novel learning algorithm, in addition to modifying network shape and size to best fit the task at hand.  The control system was tested on a simulated robot with a differential drive system (similar to that of a tank), a large sensor array, and some additional outputs.  The system performed well doing a variety of tasks, such as learning to follow a radio emitter.  Additionally results showed that only limited sensor feedback was necessary for learning, further 

\end{document}